{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzzdqKevEvzaV9JPebTyUU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psy794/stock_pjtt/blob/master/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%94%84%EB%A0%88%EC%9E%84%EB%A7%8C%EB%93%9C%EB%8A%94%EA%B3%BC%EC%A0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "mM1CH_miNBDH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QQjjUqAM2PF"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance\n",
        "!pip install finance-datareader\n",
        "!pip install pykrx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import datetime\n",
        "import pickle\n",
        "import warnings\n",
        "\n",
        "from pykrx import stock, bond\n",
        "import yfinance as yf\n",
        "import FinanceDataReader as fdr\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, Dense, Activation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "CTOXtrHGNEDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PE-Xi4wpNFaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "seed_everything(42) # Seed 고정"
      ],
      "metadata": {
        "id": "4Ay_GVITNGYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Load\n",
        "#OHLCV"
      ],
      "metadata": {
        "id": "Iw87MuAuNaU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이콘에서 제공받은 데이터 로드\n",
        "train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')"
      ],
      "metadata": {
        "id": "iGyn4rneNbxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 종목별 OHLCV 데이터를 가져오기\n",
        "def get_ohlcv(tickers, start_date, end_date):\n",
        "    price_dataframes = []\n",
        "\n",
        "    for ticker in tickers:\n",
        "        print(f'Processing {ticker}')\n",
        "        price_df = stock.get_market_ohlcv_by_date(start_date, end_date, ticker)\n",
        "        price_df.reset_index(inplace=True)\n",
        "        price_df['종목코드'] = ticker\n",
        "\n",
        "        price_dataframes.append(price_df)\n",
        "    combined_price_df = pd.concat(price_dataframes, ignore_index=True)\n",
        "\n",
        "    return combined_price_df\n",
        "\n",
        "start_date = '20210601'\n",
        "end_date = '20230728'   # ★★★★★★★ 여기 확인 및 수정 필요 ★★★★★★★\n",
        "train_tickers = train['Ticker'].unique().tolist()  # 중복 제거하여 티커 값 리스트로 변환\n",
        "train = get_ohlcv(train_tickers, start_date, end_date)"
      ],
      "metadata": {
        "id": "ZK2TbkGYNb0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# 데이터프레임을 pickle 파일로 저장 (이유: 각 종목별 OHLCV 데이터를 가져오기가 오래걸려서 (45분정도 소요))\n",
        "pickle.dump(train, open('/content/drive/MyDrive/Colab Notebooks/train_data.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "j0qZu-BpOIkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 pickle 파일 불러오기\n",
        "loaded_train = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/train_data.pkl', 'rb')"
      ],
      "metadata": {
        "id": "9l0OYKw0OK1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = loaded_train\n",
        "train"
      ],
      "metadata": {
        "id": "S0FnCZKHOK4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#이동평균, obv, forex, 스토캐스틱, 시가총액 추가"
      ],
      "metadata": {
        "id": "rwDOsyIlQqB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mv(df):\n",
        "    \"\"\"\n",
        "    이동평균을 계산하여 데이터프레임에 추가하는 함수\n",
        "\n",
        "    Parameters:\n",
        "        - df: 이동평균을 계산할 데이터프레임\n",
        "    Returns:\n",
        "        계산된 이동평균 값을 포함한 데이터프레임\n",
        "    \"\"\"\n",
        "    grouped = df.groupby('종목코드')  # 종목별로 그룹화\n",
        "    df['Close_mv5'] = grouped['종가'].rolling(5, min_periods=5).mean().reset_index(0, drop=True) # 5일 이동평균 계산\n",
        "    df['Close_mv10'] = grouped['종가'].rolling(10, min_periods=10).mean().reset_index(0, drop=True)  # 10일 이동평균 계산\n",
        "    df['Close_mv20'] = grouped['종가'].rolling(20, min_periods=20).mean().reset_index(0, drop=True)  # 20일 이동평균 계산\n",
        "\n",
        "    return df\n",
        "\n",
        "def get_obv(train):#OBV 컬럼에 추가하기\n",
        "    #종목코드 2000가지를 가져오자\n",
        "    stock_code = train['종목코드'].unique()\n",
        "\n",
        "    #데이터 프레임에 틀 만들기\n",
        "    train['OBV'] = 0\n",
        "    train['OBV_EMA'] = 0\n",
        "\n",
        "    for code in tqdm(stock_code): #각 종목별, 총 2000회 반복\n",
        "        df_train = train[train['종목코드'] == code]\n",
        "        OBV = []\n",
        "        OBV.append(0) #[-1]을 사용하기 위해 초기 값을 넣어준다.\n",
        "        for i in range(1, len(df_train['종가'])): #기간 만큼 돌려준다.\n",
        "            if df_train['종가'].iloc[1] > df_train['종가'].iloc[i-1]: #현재 종가가 전일 종가보다 크다면\n",
        "                OBV.append(OBV[-1] + df_train['거래량'].iloc[i]) #OBV 제일 마지막 값에 현재일 거래량 값을 더한 값을 OBV에 추가.\n",
        "            elif df_train['종가'].iloc[1] < df_train['종가'].iloc[i-1]: #현재 종가가 전일 종가보다 작다면\n",
        "                OBV.append(OBV[-1] - df_train['거래량'].iloc[i]) #OBV 제일 마지막 값에 현재일 거래량 값을 빼준 값을 OBV에 추가.\n",
        "            else: #종가가 동일하다면\n",
        "                OBV.append(OBV[-1]) #OBV 제일 마지막 값을 다시 한번 OBV에 추가.\n",
        "\n",
        "        train.loc[train['종목코드'] == code, 'OBV'] = OBV #OBV 리스트 안의 값을 코드에 넣어주자.\n",
        "        train.loc[train['종목코드'] == code,'OBV_EMA'] = train[train['종목코드'] == code]['OBV'].ewm(com=20).mean() #OBV의 이동평균 값을 넣어주자.\n",
        "        return train\n",
        "\n",
        "\n",
        "# forex 데이터\n",
        "def get_forex_index(df):\n",
        "    start_date_yf = '2021-06-01'\n",
        "    end_date_yf = '20230728'   # ★★★★★★★ 여기 확인 및 수정 필요 ★★★★★★★\n",
        "\n",
        "    start_date = '20210601'\n",
        "    end_date = '20230728'   # ★★★★★★★ 여기 확인 및 수정 필요 ★★★★★★★\n",
        "\n",
        "    forex_index_data = yf.download([\"USDKRW=X\", \"USDAUD=X\", \"USDJPY=X\", \"EURUSD=X\", \"CNY=X\", \"^GSPC\", \"^DJI\", \"^IXIC\", \"^STOXX50E\",\n",
        "                                   \"^SOX\",  \"000001.SS\", \"000300.SS\", \"MME=F\", \"^TNX\"],\n",
        "                                  start=start_date_yf, end=end_date_yf, rounding=True)\n",
        "\n",
        "    tmp_forex_index = forex_index_data[\"Close\"]\n",
        "    tmp_forex_index.index = pd.to_datetime(tmp_forex_index.index)\n",
        "    tmp_forex_index = tmp_forex_index[(tmp_forex_index.index >= pd.to_datetime(start_date)) &\n",
        "                                      (tmp_forex_index.index <= pd.to_datetime(end_date))]\n",
        "    tmp_forex_index.columns = [\"sse_composite_index\", \"csi300_index\", \"usdtocny\", \"eurtousd\", \"msci_emerging\",\n",
        "                               \"usdtoaud\", \"usdtojpy\", \"usdtokrw\",\n",
        "                               \"dow\", \"snp500\", \"nasdaq\", \"semicon_index\", \"euro50\", \"us10y_tsy\"]\n",
        "\n",
        "    tmp_forex_index.reset_index(drop=False, inplace=True)\n",
        "\n",
        "    merged_df = df.merge(tmp_forex_index, left_on='날짜', right_on='Date', how='left')\n",
        "    merged_df.drop(columns=['Date'], inplace=True)\n",
        "    return merged_df\n",
        "\n",
        "\n",
        "\n",
        "#스토캐스틱 fast 지표\n",
        "def sto_fast_logic(df_fast):\n",
        "    n = 14\n",
        "    m = 5\n",
        "\n",
        "    #n일중 최고가\n",
        "    ndays_high = df_fast['고가'].rolling(window = n, min_periods = 1).max()\n",
        "    #n일중 최저가\n",
        "    ndays_low = df_fast['저가'].rolling(window = n, min_periods = 1).min()\n",
        "    #Fast%K 계산\n",
        "    fast_k = ((df_fast['종가'] - ndays_low) / (ndays_high - ndays_low)) * 100\n",
        "    #Fast%D 계산\n",
        "    fast_d = fast_k.ewm(span = m).mean()\n",
        "\n",
        "    return (fast_k, fast_d)\n",
        "\n",
        "def get_sto_fast(df):\n",
        "    df['fast_k'] = 0\n",
        "    df['fast_d'] = 0\n",
        "    stock_code = df['종목코드'].unique()\n",
        "\n",
        "    for code in tqdm(stock_code): #각 종목별, 총 2000회 반복\n",
        "        df_fast = df[df['종목코드'] == code]\n",
        "        (fast_k, fast_d) = sto_fast_logic(df_fast)\n",
        "        df.loc[df['종목코드'] == code, 'fast_k'] = fast_k\n",
        "        df.loc[df['종목코드'] == code,'fast_d'] = fast_d\n",
        "    return df\n",
        "\n",
        "#스토캐스틱 slow 지표\n",
        "def sto_slow_logic(df_slow):\n",
        "    n = 14\n",
        "    m = 5\n",
        "    t = 5\n",
        "\n",
        "    #n일중 최고가\n",
        "    ndays_high = df_slow['고가'].rolling(window = n, min_periods = 1).max()\n",
        "    #n일중 최저가\n",
        "    ndays_low = df_slow['저가'].rolling(window = n, min_periods = 1).min()\n",
        "    #Fast%K 계산\n",
        "    fast_k = ((df_slow['종가'] - ndays_low) / (ndays_high - ndays_low)) * 100\n",
        "    #Slow%K 계산\n",
        "    slow_k = fast_k.ewm(span = m).mean()\n",
        "    #Slow%D 계산\n",
        "    slow_d = slow_k.ewm(span = t).mean()\n",
        "\n",
        "    return (slow_k, slow_d)\n",
        "\n",
        "def get_sto_slow(df):\n",
        "    df['slow_k'] = 0\n",
        "    df['slow_d'] = 0\n",
        "    stock_code = df['종목코드'].unique()\n",
        "\n",
        "    for code in tqdm(stock_code): #각 종목별, 총 2000회 반복\n",
        "        df_slow = df[df['종목코드'] == code]\n",
        "        (slow_k, slow_d) = sto_fast_logic(df_slow)\n",
        "        df.loc[df['종목코드'] == code, 'slow_k'] = slow_k\n",
        "        df.loc[df['종목코드'] == code,'slow_d'] = slow_d\n",
        "    return df\n",
        "\n",
        "def add_market_cap(df):\n",
        "    df['시가총액'] = 0\n",
        "\n",
        "    stock_code = df['종목코드'].unique()\n",
        "\n",
        "    for code in tqdm(stock_code): #각 종목별, 총 2000회 반복\n",
        "        market_cap = stock.get_market_cap('20210601', '20230728', str(code))      # ★★★★★★★ 여기 확인 및 수정 필요 ★★★★★★★\n",
        "        market_cap_only = list(market_cap['시가총액'])\n",
        "\n",
        "        df.loc[df['종목코드'] == code, '시가총액'] = market_cap_only\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "train = get_mv(train)\n",
        "train = get_obv(train)\n",
        "train = get_forex_index(train)\n",
        "train = get_sto_fast(train)\n",
        "train = add_market_cap(train)\n",
        "train"
      ],
      "metadata": {
        "id": "4OIl6SkyOK6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#오래걸리니까 피클로 저장\n",
        "pickle.dump(train, open('/content/drive/MyDrive/Colab Notebooks/train_data_df2.pkl', 'wb'))\n",
        "loaded_train_df = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/train_data_df2.pkl', 'rb\n",
        "loaded_train_df"
      ],
      "metadata": {
        "id": "pI6wxBHyOK8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = loaded_train_df"
      ],
      "metadata": {
        "id": "SBqXxUBAOK-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.columns)\n",
        "\n",
        "# Index(['날짜', '시가', '고가', '저가', '종가', '거래량', '거래대금', '등락률', '종목코드', 'Close_mv5',\n",
        "#        'Close_mv10', 'Close_mv20', 'OBV', 'OBV_EMA', 'sse_composite_index',\n",
        "#        'csi300_index', 'usdtocny', 'eurtousd', 'msci_emerging', 'usdtoaud',\n",
        "#        'usdtojpy', 'usdtokrw', 'dow', 'snp500', 'nasdaq', 'semicon_index',\n",
        "#        'euro50', 'us10y_tsy', 'fast_k', 'fast_d', '시가총액'],\n",
        "#       dtype='object')"
      ],
      "metadata": {
        "id": "dcYpjEwjOqSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#이후  OBV 수정하고, slow_k, slow_d 추가한 버전으로 데이터프레임 업데이트 (by재훈)"
      ],
      "metadata": {
        "id": "yyR917Q6QWlf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DUAmCiCZOqVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KimC8dFSOqXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p10jN9XWOqZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7월20일부터 추가되는 코드 적어둘 곳 (원자재, 뉴스감성분석 등)"
      ],
      "metadata": {
        "id": "MoiEf55cRXZY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4AlAQnCQRdi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2BYUQiyRdle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mfIjGjbRdn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zeGedBr7Rdyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#업종은 마지막에 merge하면 됨 (on = '종목코드')"
      ],
      "metadata": {
        "id": "MdsHCRGCQbfC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wltDCk_8OqcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ocbfljl7OqeW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}